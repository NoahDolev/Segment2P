{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segment 2p - Simple Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "### Step 1: Organize training dataset\n",
    "\n",
    "The model accepts files organized into the following directory structure:\n",
    "\n",
    "..... Train   \n",
    "..... Train_Annotation   \n",
    "..... Validation   \n",
    "..... Validation_Annotation\n",
    "\n",
    "In the train directory there should be jpg files with the micrographs for training. In train annotation, ground truth segmentation should appear as PNGs with the same name as their respective image in the train folder. These ground truths should have a value of zero for regions that are _not_ of interest and one for regions of interest. Same goes for validation and validation_annotation. These files should appear in an S3 bucket. \n",
    "\n",
    "### Step 2: Setup model for training\n",
    "\n",
    "To setup a model for training we first, setup an estimator object: \n",
    "```{Python}\n",
    "ss_model = sagemaker.estimator.Estimator(...\n",
    "```\n",
    "Then we set the hyperparameters:\n",
    "```Python}\n",
    "ss_model.set_hyperparameters(backbone='resnet-101', # This is the encoder. Other option is resnet-50\n",
    "                             algorithm='deeplab', # This is the decoder. Other option is 'psp' and 'deeplab'    \n",
    "                             use_pretrained_model='False'...\n",
    "```\n",
    "See [Training](#Training) for a full demonstration.    \n",
    "\n",
    "### Step 3: Run model training on data\n",
    "Now we feed the model the data for training by setting up a dictionary as follows:   \n",
    "```Python}\n",
    "data_channels = {'train': train_data, \n",
    "                 'validation': validation_data,\n",
    "                 'train_annotation': train_annotation, \n",
    "                 'validation_annotation':validation_annotation}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import io\n",
    "import boto3\n",
    "import numpy as np\n",
    "from skimage import util \n",
    "from skimage.util import img_as_ubyte\n",
    "from skimage import exposure\n",
    "from skimage.io import imread as pngread\n",
    "from skimage.io import imsave as pngsave\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from skimage import color\n",
    "\n",
    "import cv2\n",
    "from rolling_ball_filter import rolling_ball_filter\n",
    "import random\n",
    "import threading\n",
    "\n",
    "from processfiles import *\n",
    "role = get_execution_role()\n",
    "print(role)\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "training_image = get_image_uri(sess.boto_region_name, 'semantic-segmentation', repo_version=\"latest\")\n",
    "print (training_image)\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "s3_resource = boto3.resource('s3')\n",
    "s3meadata = s3_resource.Bucket(name='meadata')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "_Setup of our original training set_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Run process functions (raw and filtered versions of fig8 and liorP)\n",
    "def procfilepar(key):\n",
    "    proccessliorpreprocfiles(key)\n",
    "    proccessliorfiles(key)\n",
    "    proccessfigure8files(key)\n",
    "    proccessfig8preprocfiles(key)\n",
    "    proccessusiigacifiles(key)\n",
    "    proccesshelafiles(key)\n",
    "    \n",
    "keys = [obj.key for obj in s3meadata.objects.all()]\n",
    "for key in keys:\n",
    "    t = threading.Thread(target = procfilepar, args=(key,)).start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crop dataset images around labeled areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = [obj.key for obj in s3_resource.Bucket(name=bucket).objects.all() if ('jpg' in obj.key and prefix in obj.key)]\n",
    "for key in keys:\n",
    "     t = threading.Thread(target = performcrop, args=(key,)).start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete all files without a matching image-annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "removeunmatched()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove samples with few acceptable ground truth segmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "train_channel = prefix + '/train'\n",
    "validation_channel = prefix + '/validation'\n",
    "train_annotation_channel = prefix + '/train_annotation'\n",
    "validation_annotation_channel = prefix + '/validation_annotation'\n",
    "keys = [obj.key for obj in s3_resource.Bucket(name=bucket).objects.all() if ('png' in obj.key and prefix in obj.key)]\n",
    "segs = []\n",
    "empties = []\n",
    "for key in keys:\n",
    "    masksavepath = \"/tmp/\"+key.split('/')[-1]\n",
    "    s3.meta.client.download_file(bucket, key , masksavepath)\n",
    "    mask = cv2.imread(masksavepath)\n",
    "    segs.append([np.sum(mask==1)])\n",
    "    empties.append([np.sum(mask==0)])\n",
    "\n",
    "ratio = ((np.asarray(segs)/np.asarray(empties))*100).ravel()\n",
    "thresh = np.round(np.mean(ratio)-np.std(ratio))\n",
    "# plt.hist(ratio)\n",
    "# plt.show()\n",
    "df = pd.DataFrame({'key':keys, 'ratio':ratio,'empty':ratio<thresh})\n",
    "removesamples = df['key'].loc[np.where(df['empty'].values)].values\n",
    "for removeme in removesamples:\n",
    "    boto3.client('s3').delete_object(Bucket = bucket, Key = removeme)\n",
    "    boto3.client('s3').delete_object(Bucket = bucket, Key = removeme.replace('_annotation/','/').replace('png','jpg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------\n",
    "_Finished setup of training set from article_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image types and output location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "label_map = { \"scale\": 1 }\n",
    "with open('train_label_map.json', 'w') as lm_fname:\n",
    "    json.dump(label_map, lm_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_output_location = 's3://{}/{}/output'.format(bucket, prefix)\n",
    "print(s3_output_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Model Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the sagemaker estimator object.\n",
    "ss_model = sagemaker.estimator.Estimator(training_image,\n",
    "                                         role, \n",
    "                                         train_instance_count = 1, \n",
    "                                         train_instance_type = 'ml.p3.16xlarge',\n",
    "                                         train_volume_size = 300, # size in gb on s3 to reserve\n",
    "                                         train_max_run = 360000,\n",
    "                                         output_path = s3_output_location,\n",
    "                                         base_job_name = 'segment2p_train',\n",
    "                                         sagemaker_session = sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup hyperparameters \n",
    "import boto3\n",
    "s3traindata = boto3.resource('s3').Bucket(name=bucket)\n",
    "numtrain = len([obj.key for obj in s3traindata.objects.all() if ('train/' in obj.key and 'jpg' in obj.key)])\n",
    "ss_model.set_hyperparameters(backbone='resnet-101', # This is the encoder. Other option is resnet-50\n",
    "                             algorithm='deeplab', # This is the decoder. Other option is 'psp' and 'deeplab'                             \n",
    "                             use_pretrained_model='False', # Use the pre-trained model.\n",
    "                             crop_size=412, # Size of image random crop.                             \n",
    "                             num_classes=2, # Background + cell \n",
    "                             epochs=1000, # Number of epochs to run.\n",
    "                             learning_rate=0.003037052721870563, \n",
    "                             momentum = 0.6133596510181524, \n",
    "                             weight_decay = 0.0001560844683426084,                           \n",
    "                             optimizer='adagrad', # Other options include 'adam', 'rmsprop', 'nag', 'adagrad'.\n",
    "                             lr_scheduler='poly', # Other options include 'cosine' and 'step'.                           \n",
    "                             mini_batch_size=35, # Setup some mini batch size.\n",
    "                             validation_mini_batch_size=16, #try larger batch sizes maybe? \n",
    "                             early_stopping=True, # Turn on early stopping. If OFF, other early stopping parameters are ignored.\n",
    "                             early_stopping_patience=50, # Tolerate these many epochs if the mIoU doens't increase.\n",
    "                             early_stopping_min_epochs=25, # No matter what, run these many number of epochs.                             \n",
    "                             num_training_samples=numtrain) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup data inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create full bucket names\n",
    "s3_train_data = 's3://{}/{}'.format(bucket, train_channel)\n",
    "s3_validation_data = 's3://{}/{}'.format(bucket, validation_channel)\n",
    "s3_train_annotation = 's3://{}/{}'.format(bucket, train_annotation_channel)\n",
    "s3_validation_annotation = 's3://{}/{}'.format(bucket, validation_annotation_channel)\n",
    "\n",
    "distribution = 'FullyReplicated'\n",
    "# Create sagemaker s3_input objects\n",
    "train_data = sagemaker.session.s3_input(s3_train_data, distribution=distribution, \n",
    "                                        content_type='image/jpeg', s3_data_type='S3Prefix')\n",
    "validation_data = sagemaker.session.s3_input(s3_validation_data, distribution=distribution, \n",
    "                                        content_type='image/jpeg', s3_data_type='S3Prefix')\n",
    "train_annotation = sagemaker.session.s3_input(s3_train_annotation, distribution=distribution, \n",
    "                                        content_type='image/png', s3_data_type='S3Prefix')\n",
    "validation_annotation = sagemaker.session.s3_input(s3_validation_annotation, distribution=distribution, \n",
    "                                        content_type='image/png', s3_data_type='S3Prefix')\n",
    "\n",
    "data_channels = {'train': train_data, \n",
    "                 'validation': validation_data,\n",
    "                 'train_annotation': train_annotation, \n",
    "                 'validation_annotation':validation_annotation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "ss_model.fit(inputs=data_channels, logs=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
